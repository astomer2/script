{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "now_times = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path= '/mnt/nas1/lanwei-125/FGF5/disulfide/disulfide_peptide_cluster/cluster_0/all_refinement/'\n",
    "result_path = f'{dir_path}/refinement/'\n",
    "protein_pdb = '/mnt/nas1/lanwei-125/FGF5/dock_prepare/FGF5.pdb'\n",
    "protein_chain = \"A\"\n",
    "peptide_chain = \"E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/nas1/lanwei-125/FGF5/disulfide/disulfide_peptide_cluster/cluster_0/all_refinement/cluster_0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dir_names = [\n",
    "    dir_name for dir_name in Path(dir_path).iterdir()\n",
    "    if dir_name.is_dir() and dir_name.name.split(\"_\")[0] == \"cluster\"\n",
    "]\n",
    "\n",
    "pdb_names = [\n",
    "    file.stem for cluster_dir in cluster_dir_names\n",
    "    for file in cluster_dir.iterdir() if file.is_file() and file.suffix == \".pdb\"\n",
    "    ]\n",
    "[str(cluster_dir_name) for cluster_dir_name in cluster_dir_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_lines = []\n",
    "protein_chain = set()\n",
    "with open(protein_pdb) as f:\n",
    "    protein_lines = [line for line in f if line.startswith(\"ATOM\") or line.startswith(\"TER\")]\n",
    "    for line in protein_lines:\n",
    "        if line.startswith('ATOM') :\n",
    "            chains = line[21]\n",
    "            protein_chain.add(chains)\n",
    "protein_chain_str = ','.join(protein_chain)\n",
    "\n",
    "peptide_chain = set()\n",
    "peptide_chain_str = ''\n",
    "for cluster_dir_name in cluster_dir_names:\n",
    "    pdb_path = Path(dir_path) / cluster_dir_name\n",
    "    for pdb_file in pdb_path.glob('*.pdb'):\n",
    "        parts = pdb_file.stem.split(\"_\")\n",
    "        if len(parts) >= 2 and parts[1] == \"ref\":\n",
    "            continue\n",
    "\n",
    "        if pdb_file.suffix == '.pdb' and '_ref' not in pdb_file.stem:\n",
    "            # Read peptide lines\n",
    "            peptide_lines = []\n",
    "            with open(pdb_file) as f:\n",
    "                peptide_lines = [line for line in f if line.startswith(\"ATOM\")]\n",
    "                for line in peptide_lines:\n",
    "                    if line.startswith('ATOM') :\n",
    "                        chains = line[21]\n",
    "                        peptide_chain.add(chains)\n",
    "            peptide_chain_str = ','.join(peptide_chain)\n",
    "\n",
    "            # Write to new pdb file\n",
    "            os.makedirs(pdb_path / pdb_file.stem, exist_ok=True)\n",
    "            new_pdb_path = pdb_path / pdb_file.stem / (pdb_file.stem + '_ref.pdb')\n",
    "            if new_pdb_path.exists():\n",
    "                logger.info(f'{now_times}: {new_pdb_path} already exists')\n",
    "                continue\n",
    "            with open(new_pdb_path, 'w') as f:\n",
    "                f.write(''.join(protein_lines))\n",
    "                if protein_lines[-1].startswith('END'):\n",
    "                    #删除END语句\n",
    "                    del protein_lines[-1]\n",
    "                if not protein_lines[-1].startswith('TER'):\n",
    "                    f.write(\"\\nTER\\n\")\n",
    "                f.write(''.join(peptide_lines))\n",
    "                f.write(\"\\nTER\\n\")\n",
    "                f.write(\"END\\n\")\n",
    "\n",
    "            logger.info(f'{now_times}: processing {pdb_file} to {new_pdb_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_dir_name in cluster_dir_names:\n",
    "\n",
    "    for file in (Path(dir_path) / cluster_dir_name).glob('*.pdb'):\n",
    "        pdb_file = file.stem\n",
    "       \n",
    "        work_dir = Path(dir_path) / cluster_dir_name / pdb_file\n",
    "        for file in work_dir.glob('*.pdb'):\n",
    "            refine_parts = file.stem.split('_')\n",
    "            if len(refine_parts) >= 2 and refine_parts[1] == 'ref':\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_dir_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m np_nums \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster_dir_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcluster_dir_names\u001b[49m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m (Path(dir_path) \u001b[38;5;241m/\u001b[39m cluster_dir_name)\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.pdb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      5\u001b[0m         pdb_file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mstem\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_dir_names' is not defined"
     ]
    }
   ],
   "source": [
    "np_nums = \"24\"\n",
    "for cluster_dir_name in cluster_dir_names:\n",
    "\n",
    "    for file in (Path(dir_path) / cluster_dir_name).glob('*.pdb'):\n",
    "        pdb_file = file.stem\n",
    "       \n",
    "        work_dir = Path(dir_path) / cluster_dir_name / pdb_file\n",
    "        os.chdir(work_dir)\n",
    "        for file in work_dir.glob('*.pdb'):\n",
    "            if ('-ref' in file.stem) and ('_0250' not in file.stem):    \n",
    "                ref_pdb = file.stem\n",
    "                logger.info(f'{now_times}: processing {file}')\n",
    "\n",
    "                f=open('prepack.flags', 'w')\n",
    "                f.write(\"-s \"+ ref_pdb + \".pdb \\n\")\n",
    "                f.write(\"-flexpep_prepack \\n\")\n",
    "                f.write(\"-nstruct 1 \\n\")\n",
    "                f.write(\"-ex1 \\n\")\n",
    "                f.write(\"-ex2aro \\n\")\n",
    "                f.write(\"-mute core.io.database \\n\")\n",
    "                f.write(\"-mute core.util.prof \\n\")\n",
    "                f.write(\"-mute protocols.jd2.JobDistributor \\n\")\n",
    "                f.write(\"-scorefile pack.score.sc \")\n",
    "                f.close()\n",
    "                os.system(\"mpirun -np \"+ np_nums + \" FlexPepDocking.mpi.linuxgccrelease @prepack.flags 2>&1 \")\n",
    "\n",
    "                f=open('refinement.flags', 'w')\n",
    "                f.write(\"-s \"+ ref_pdb + \"_0001.pdb \\n\")\n",
    "                #f.write(\"-native \"+ peptide + \".pdb \\n\")\n",
    "                f.write(\"-flexPepDocking:receptor_chain \"+protein_chain_str+\" \\n\")\n",
    "                f.write(\"-flexPepDocking:peptide_chain \"+peptide_chain_str+\" \\n\")\n",
    "                f.write(\"-pep_refine \\n\")\n",
    "                f.write(\"-use_input_sc \\n\")\n",
    "                f.write(\"-nstruct 250 \\n\")\n",
    "                f.write(\"-scorefile refinement.score.sc \\n\")\n",
    "                f.write(\"-ex1 \\n\")\n",
    "                f.write(\"-ex2aro \\n\")\n",
    "                f.write(\"-mute core.io.database \\n\")\n",
    "                f.write(\"-mute core.util.prof \\n\")\n",
    "                f.write(\"-mute protocols.jd2.JobDistributor \")\n",
    "                f.close()\n",
    "                os.system(\" mpirun.openmpi -np \"+ np_nums + \" FlexPepDocking.mpi.linuxgccrelease @refinement.flags 2>&1  \")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = Path(result_path)\n",
    "if not result_path.exists():\n",
    "    result_path.mkdir()\n",
    "\n",
    "\n",
    "for file in (Path(dir_path) / cluster_dir_name).glob('*.pdb'):\n",
    "    pdb_file = file.stem\n",
    "    work_dir = Path(dir_path) / cluster_dir_name / pdb_file  \n",
    "    score_file = work_dir / 'refinement.score.sc'\n",
    "\n",
    "    with open(score_file, 'r') as f:\n",
    "        headers = None\n",
    "        rows = []\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('SEQUENCE:'):\n",
    "                continue\n",
    "            elif line.startswith('SCORE:'):\n",
    "                if headers is None:\n",
    "                    headers = line.split()[1:]\n",
    "                else:\n",
    "                    rows.append(line.split()[1:])\n",
    "            else:\n",
    "                rows.append(line.split())\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "        df['reweighted_sc'] = df['reweighted_sc'].astype(float)\n",
    "        df = df.sort_values(by='reweighted_sc', ignore_index=True)\n",
    "        min_row = df.loc[df['reweighted_sc'].idxmin()]\n",
    "\n",
    "    candidate_path = work_dir / f\"{min_row['description']}.pdb\"\n",
    "    shutil.copy(candidate_path, result_path)\n",
    "\n",
    "    result_score_file = result_path / 'candidate.txt'\n",
    "    with open(result_score_file, 'a') as f:\n",
    "        f.write(f\"{min_row['description']}\\t{min_row['reweighted_sc']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_peptide.pdb_fixer import fixed_pdb_file\n",
    "for file_entry in Path(result_path).iterdir():\n",
    "    if file_entry.suffix == '.pdb':\n",
    "        processed_pdb_path = Path(result_path) / file_entry.name\n",
    "        candidate_pdb_path = Path(result_path) / f\"{file_entry.stem.split('-')[0]}.pdb\"\n",
    "        candidate_pdb = []\n",
    "\n",
    "        with open(processed_pdb_path) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith('ATOM') or line.startswith('TER') or line.startswith('END'):\n",
    "                    candidate_pdb.append(line)\n",
    "\n",
    "        with open(candidate_pdb_path, 'w') as f:\n",
    "            f.write(''.join(candidate_pdb))\n",
    "\n",
    "        fixed_pdb_file(candidate_pdb_path,result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "\n",
    "candidate_txt = Path(\"/mnt/nas1/lanwei-125/FGF5/disulfide/disulfide_peptide_cluster/cluster_0/all_refinement/refined/candidate.txt\")\n",
    "with open(candidate_txt, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    c = []\n",
    "for line in lines:\n",
    "    a = line.split()[0].split(\"-\")[0]\n",
    "    b = line.split()[1]\n",
    "    if log10(abs(float(b))) < 4:\n",
    "        newline = a + \" \" + b \n",
    "        c.append(newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNNILCPT',\n",
       " 'EKCLGAFCFRRD',\n",
       " 'QCNVPSCLT',\n",
       " 'GKCHAAFCFRRD',\n",
       " 'CTDKNCPLG',\n",
       " 'CNSINCPLG',\n",
       " 'GSCFDKECFRRD',\n",
       " 'PCIGNTCPLG',\n",
       " 'SCANINCGL',\n",
       " 'CYIQECKLG',\n",
       " 'CNGLPCVE',\n",
       " 'GSCFGASCPRSI',\n",
       " 'CTWSNCPLG',\n",
       " 'CYKPDCPLG',\n",
       " 'CYATWCPLG',\n",
       " 'GSCSGAFCPRSI']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(c)\n",
    "d = df1[0].str.split(' ', expand=True)\n",
    "df1['seq'] = d[0]\n",
    "df1['value'] = d[1]\n",
    "df1 = df1.drop(columns=[0])\n",
    "df1.sort_values(by=['value'], inplace=True,ascending=False)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1 = df1.iloc[:16]\n",
    "a = df1['seq'].tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GSCFDKECFRRD'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = Path('/mnt/nas1/lanwei-125/FGF5/disulfide/MD/v1/')\n",
    "s = []\n",
    "for flie in v1.glob('*.pdb'):\n",
    "    s.append(flie.stem)\n",
    "set(a) & set(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "\n",
    "candidate_txt = Path(\"/mnt/nas1/lanwei-125/FGF5/disulfide/disulfide_peptide_cluster/cluster_0/all_refinement/refined/candidate.txt\")\n",
    "with open(candidate_txt, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    c = []\n",
    "for line in lines:\n",
    "    a = line.split()[0].split(\"-\")[0]\n",
    "    b = line.split()[1]\n",
    "    if log10(abs(float(b))) < 4:\n",
    "        newline = a + \" \" + b \n",
    "        c.append(newline)\n",
    "df1 = pd.DataFrame(c)\n",
    "d = df1[0].str.split(' ', expand=True)\n",
    "df1['seq'] = d[0]\n",
    "df1['value'] = d[1]\n",
    "df1 = df1.drop(columns=[0])\n",
    "df1.sort_values(by=['value'], inplace=True,ascending=False)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1 = df1.iloc[:16]\n",
    "for seq in df1['seq']:\n",
    "    os.umask(0) \n",
    "    HPEP = candidate_txt.parent/(seq + \".pdb\")\n",
    "    hpep_md = \"/mnt/nas1/lanwei-125/FGF5/disulfide/MD/v3/\"\n",
    "    os.makedirs(hpep_md, exist_ok=True)\n",
    "    shutil.copy(HPEP, hpep_md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmberTools20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
